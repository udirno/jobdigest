---
phase: 04-ai-scoring
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/api/claude-client.js
  - src/job-scorer.js
autonomous: true

must_haves:
  truths:
    - "A single job can be scored 0-100 against a resume via Claude API"
    - "Score includes reasoning text explaining the match quality"
    - "Score evaluates all 5 dimensions: skills match, experience level, tech stack alignment, title relevance, industry fit"
    - "Failed scoring marks job as unscored rather than crashing"
    - "Resume content is cached across sequential scoring requests for cost efficiency"
  artifacts:
    - path: "src/api/claude-client.js"
      provides: "Claude API wrapper with structured outputs and prompt caching"
      exports: ["scoreJob"]
      min_lines: 80
    - path: "src/job-scorer.js"
      provides: "Scoring orchestrator that processes unscored jobs sequentially"
      exports: ["scoreUnscoredJobs", "scoreSingleJob"]
      min_lines: 60
  key_links:
    - from: "src/api/claude-client.js"
      to: "https://api.anthropic.com/v1/messages"
      via: "fetch with structured outputs"
      pattern: "api\\.anthropic\\.com.*messages"
    - from: "src/api/claude-client.js"
      to: "src/errors.js"
      via: "retryWithBackoff and createApiError"
      pattern: "retryWithBackoff|createApiError"
    - from: "src/job-scorer.js"
      to: "src/api/claude-client.js"
      via: "scoreJob import"
      pattern: "import.*scoreJob.*claude-client"
    - from: "src/job-scorer.js"
      to: "src/storage.js"
      via: "getJobs, saveJob, getResume, getApiKeys"
      pattern: "storage\\.(getJobs|saveJob|getResume|getApiKeys)"
---

<objective>
Create the Claude API scoring client and job scorer orchestrator -- the core AI scoring engine for JobDigest.

Purpose: This is the heart of Phase 4. The Claude client wraps the Anthropic Messages API with structured outputs to guarantee valid JSON scoring responses, prompt caching for 90% cost reduction on resume tokens, and retry logic for rate limits. The job scorer orchestrates scoring across all unscored jobs sequentially, saving each score immediately for checkpoint resilience.

Output: Two new modules -- `src/api/claude-client.js` (API wrapper) and `src/job-scorer.js` (orchestrator) -- ready to be wired into the fetch pipeline in Plan 02.
</objective>

<execution_context>
@/Users/udirno/.claude/get-shit-done/workflows/execute-plan.md
@/Users/udirno/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-ai-scoring/04-RESEARCH.md

# Existing patterns to follow
@src/api/adzuna.js
@src/errors.js
@src/storage.js
@src/keep-alive.js
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Claude API scoring client with structured outputs and prompt caching</name>
  <files>src/api/claude-client.js</files>
  <action>
Create `src/api/claude-client.js` following the existing API client pattern from `adzuna.js`. This module wraps the Claude Messages API for job-resume scoring.

**Function: `scoreJob(job, resume, apiKey)`**

Request structure:
- Model: `claude-haiku-4-5`
- Max tokens: 512 (sufficient for structured scoring output)
- API version header: `anthropic-version: 2023-06-01`
- DO NOT use assistant message prefilling (incompatible with structured outputs per research)

Structured output schema (`output_config.format.type: 'json_schema'`):
```json
{
  "type": "object",
  "properties": {
    "score": { "type": "integer", "minimum": 0, "maximum": 100 },
    "reasoning": { "type": "string" },
    "skills_match": { "type": "integer", "minimum": 0, "maximum": 100 },
    "experience_level": { "type": "integer", "minimum": 0, "maximum": 100 },
    "tech_stack_alignment": { "type": "integer", "minimum": 0, "maximum": 100 },
    "title_relevance": { "type": "integer", "minimum": 0, "maximum": 100 },
    "industry_fit": { "type": "integer", "minimum": 0, "maximum": 100 }
  },
  "required": ["score", "reasoning", "skills_match", "experience_level", "tech_stack_alignment", "title_relevance", "industry_fit"],
  "additionalProperties": false
}
```

System prompt (2 blocks, both with `cache_control: { type: 'ephemeral' }`):
1. Scoring instructions block -- Defines the role as expert technical recruiter. Per user decision: skills-heavy weighting. Use this breakdown:
   - Skills and Tech Stack: 60% (primary factor per user decision)
   - Experience Level: 15%
   - Job Title Relevance: 10%
   - Industry Fit: 10%
   - Other Factors: 5%
   Include scoring guidelines (90-100 excellent, 70-89 strong, 50-69 moderate, 30-49 weak, 0-29 poor). Instruct for concise reasoning (2-3 sentences focusing on strengths and gaps).

2. Resume content block -- `Candidate Resume:\n\n${resume}` with `cache_control: { type: 'ephemeral' }` for prompt caching (5-minute TTL, 90% cost reduction after first request).

User message:
- Per user decision: send core sections only, skip benefits/perks/culture fluff
- Create helper function `extractJobCore(job)` that extracts: title, company, description (full text -- let Claude parse the relevant sections rather than fragile regex). Include location and salary range if available for context.

Retry logic:
- Use existing `retryWithBackoff` from `errors.js` wrapping the fetch call
- Use `createApiError` from `errors.js` for non-ok responses (follows adzuna.js pattern)
- On final failure after retries, return `{ score: null, reasoning: 'Scoring failed after retries', error: error.message }` instead of throwing

Usage logging:
- After successful response, log `input_tokens`, `cache_creation_input_tokens`, `cache_read_input_tokens`, `output_tokens` for monitoring cache hit rates

Parse response: `JSON.parse(data.content[0].text)` to extract the structured scoring object.

Export: `scoreJob` function and `extractJobCore` helper (for potential reuse in Phase 7).
  </action>
  <verify>
Read the file and verify:
1. Uses `output_config` with `json_schema` type (not prompt-only JSON)
2. System prompt has two blocks both with `cache_control: { type: 'ephemeral' }`
3. Skills/tech stack weighted at 60% in prompt
4. Uses `retryWithBackoff` from `errors.js` (not custom retry)
5. Returns null score object on final failure (does not throw)
6. Model is `claude-haiku-4-5`
7. No assistant message prefilling
  </verify>
  <done>
claude-client.js exports scoreJob function that calls Claude API with structured outputs and prompt caching, handles errors gracefully, and returns scoring object with score (0-100), reasoning, and 5 dimension scores.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create job scorer orchestrator with sequential processing and checkpoint save</name>
  <files>src/job-scorer.js</files>
  <action>
Create `src/job-scorer.js` that orchestrates scoring across unscored jobs.

**Function: `scoreUnscoredJobs()`**

1. Load resume via `storage.getResume()`. If no resume stored, return early with `{ status: 'no_resume', scored: 0, message: 'No resume uploaded. Upload a resume in Settings to enable scoring.' }`.

2. Load API key via `storage.getApiKeys()`. If no Claude key, return early with `{ status: 'no_api_key', scored: 0, message: 'Claude API key not configured. Add it in Settings.' }`.

3. Load all jobs via `storage.getJobs()`. Filter to unscored jobs: those where `job.score === null` or `job.score === undefined`.

4. If no unscored jobs, return `{ status: 'none_to_score', scored: 0, message: 'All jobs already scored.' }`.

5. Score sequentially (Tier 1 rate limits = 50 RPM, sequential is safest):
   - For each unscored job, call `scoreJob(job, resume.text, apiKey)` from claude-client.js
   - On success: update job with `score`, `scoreReasoning` (the reasoning text), `scoredAt` (ISO timestamp), and `scoreDetails` (object with skills_match, experience_level, tech_stack_alignment, title_relevance, industry_fit)
   - Save immediately after each job scored via `storage.saveJob(jobId, updatedJob)` for checkpoint resilience
   - If scoreJob returns `{ score: null }` (failure), set `job.score = -1` as sentinel for "scoring attempted but failed", set `job.scoreReasoning = result.reasoning || 'Scoring failed'`, save, and continue to next job
   - Track counts: `scored`, `failed`, `total`
   - Add 500ms delay between requests to stay well within rate limits (50 RPM = ~1.2 req/sec, 500ms gives comfortable margin)

6. Return result object: `{ status: 'complete', scored: N, failed: N, total: N }`.

**Function: `scoreSingleJob(jobId)`**

Convenience function to re-score a single job:
1. Load resume and API key (same validation as above)
2. Load specific job from storage
3. Call scoreJob, update job, save to storage
4. Return the updated job

Export both functions.

IMPORTANT: This module does NOT manage keep-alive or batch progress. That is handled by the integration layer in Plan 02. This module is a pure scoring orchestrator.
  </action>
  <verify>
Read the file and verify:
1. scoreUnscoredJobs checks for resume and API key before proceeding
2. Filters jobs where score is null/undefined
3. Scores sequentially with 500ms delay between requests
4. Saves each job immediately after scoring (checkpoint pattern)
5. Failed scores set score to -1 sentinel (not null, which means unscored)
6. Returns structured result with status, scored count, failed count
7. Does NOT import keep-alive (handled by integration layer)
  </verify>
  <done>
job-scorer.js exports scoreUnscoredJobs (batch) and scoreSingleJob (individual) functions that orchestrate Claude API scoring with graceful error handling, immediate checkpoint saves, and rate limit-safe sequential processing.
  </done>
</task>

</tasks>

<verification>
1. Both files exist and export their documented functions
2. claude-client.js uses structured outputs (output_config with json_schema)
3. claude-client.js uses prompt caching (cache_control on system blocks)
4. job-scorer.js filters for unscored jobs and processes sequentially
5. job-scorer.js saves after each score for checkpoint resilience
6. Error handling is graceful -- no unhandled throws that would crash the pipeline
7. No circular dependencies between the two new modules
</verification>

<success_criteria>
- src/api/claude-client.js exists with scoreJob export using structured outputs and prompt caching
- src/job-scorer.js exists with scoreUnscoredJobs and scoreSingleJob exports
- Scoring uses Haiku 4.5 model with skills-heavy (60%) weighting per user decision
- Failed scoring produces sentinel value (-1) not crash
- Each scored job is saved immediately for checkpoint resilience
- 500ms delay between requests for rate limit safety
</success_criteria>

<output>
After completion, create `.planning/phases/04-ai-scoring/04-01-SUMMARY.md`
</output>
